#!/usr/bin/env python3
"""
éªŒè¯åè°ƒå™¨
åè°ƒæ‰€æœ‰éªŒè¯å™¨æ‰§è¡Œå®Œæ•´çš„æ•°æ®äº¤å‰éªŒè¯æµç¨‹
"""

import logging
import json
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path
import os

from .data_validator import XBRLDataValidator, ValidationResult
from .sec_cross_validator import SECCrossValidator
from .historical_validator import HistoricalValidator, TrendAnalysis

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ValidationOrchestrator:
    """éªŒè¯åè°ƒå™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰éªŒè¯æµç¨‹"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–éªŒè¯åè°ƒå™¨
        
        Args:
            config: éªŒè¯é…ç½®
        """
        self.config = config or {}
        
        # åˆå§‹åŒ–éªŒè¯å™¨
        self.data_validator = XBRLDataValidator(
            tolerance=self.config.get('tolerance', 0.01)
        )
        self.sec_validator = SECCrossValidator(
            user_agent=self.config.get('user_agent', 'XBRL Validator (analysis@example.com)')
        )
        self.historical_validator = HistoricalValidator(
            outlier_threshold=self.config.get('outlier_threshold', 2.5),
            min_historical_years=self.config.get('min_historical_years', 3)
        )
        
        # éªŒè¯ç»“æœå­˜å‚¨
        self.validation_results = {}
        self.reports_generated = []
    
    def validate_xbrl_document(self, 
                              xbrl_data: Dict[str, Any],
                              company_info: Dict[str, Any],
                              historical_data: List[Dict[str, Any]] = None,
                              sec_accession_number: str = None,
                              sec_api_client = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œå®Œæ•´çš„XBRLæ–‡æ¡£éªŒè¯
        
        Args:
            xbrl_data: XBRLè§£æçš„è´¢åŠ¡æ•°æ®
            company_info: å…¬å¸ä¿¡æ¯å­—å…¸
            historical_data: å†å²è´¢åŠ¡æ•°æ®ï¼ˆå¯é€‰ï¼‰
            sec_accession_number: SECæ–‡ä»¶ç¼–å·ï¼ˆç”¨äºå¤–éƒ¨éªŒè¯ï¼‰
            
        Returns:
            å®Œæ•´çš„éªŒè¯ç»“æœ
        """
        company_name = company_info.get('name', 'Unknown Company')
        fiscal_year = company_info.get('fiscal_year', datetime.now().year)
        cik = company_info.get('cik')
        
        logger.info(f"å¼€å§‹éªŒè¯ {company_name} {fiscal_year} å¹´åº¦è´¢åŠ¡æ•°æ®...")
        
        # åˆå§‹åŒ–éªŒè¯ç»“æœ
        validation_summary = {
            'company_name': company_name,
            'fiscal_year': fiscal_year,
            'cik': cik,
            'validation_timestamp': datetime.now().isoformat(),
            'overall_confidence_score': 0.0,
            'validation_status': 'UNKNOWN',
            'validation_components': {},
            'issues_found': [],
            'recommendations': []
        }
        
        try:
            # 1. å†…éƒ¨æ•°æ®ä¸€è‡´æ€§éªŒè¯
            logger.info("æ‰§è¡Œå†…éƒ¨æ•°æ®ä¸€è‡´æ€§éªŒè¯...")
            internal_result = self.data_validator.validate_financial_data(xbrl_data)
            validation_summary['validation_components']['internal_consistency'] = {
                'passed': internal_result.is_valid,
                'confidence_score': internal_result.confidence_score,
                'errors': internal_result.errors,
                'warnings': internal_result.warnings
            }
            
            # 2. SECå¤–éƒ¨æ•°æ®éªŒè¯ï¼ˆä¼˜å…ˆä½¿ç”¨APIï¼Œå…¶æ¬¡æ˜¯æ–‡ä»¶æ•°æ®ï¼‰
            sec_validation_result = None
            sec_api_validation_result = None
            
            # 2a. SEC APIéªŒè¯ï¼ˆå¦‚æœæä¾›äº†APIå®¢æˆ·ç«¯ï¼‰
            if sec_api_client and cik:
                logger.info("æ‰§è¡ŒSEC APIæ•°æ®éªŒè¯...")
                try:
                    api_comparison = self.sec_validator.validate_against_sec_api_data(
                        xbrl_data=xbrl_data,
                        sec_api_client=sec_api_client,
                        company_cik=cik,
                        fiscal_year=fiscal_year,
                        report_type='10-K'
                    )
                    
                    if api_comparison and api_comparison['api_match_rate'] > 0:
                        validation_summary['validation_components']['sec_api_external'] = {
                            'match_rate': api_comparison['api_match_rate'],
                            'matches': len(api_comparison['api_matches']),
                            'mismatches': len(api_comparison['api_mismatches']),
                            'missing_in_api': len(api_comparison['missing_in_api']),
                            'query_success_rate': sum(1 for q in api_comparison.get('api_query_details', []) if q.get('query_successful', False)) / len(api_comparison.get('api_query_details', [])) if api_comparison.get('api_query_details') else 0,
                            'comparison_details': api_comparison
                        }
                        sec_api_validation_result = api_comparison
                        logger.info(f"SEC APIéªŒè¯å®Œæˆï¼ŒåŒ¹é…ç‡: {api_comparison['api_match_rate']:.1%}")
                    else:
                        logger.warning("SEC APIéªŒè¯æœªè¿”å›æœ‰æ•ˆæ•°æ®")
                except Exception as e:
                    logger.error(f"SEC APIéªŒè¯å¤±è´¥: {e}")
            
            # 2b. SECæ–‡ä»¶æ•°æ®éªŒè¯ï¼ˆå¦‚æœæä¾›äº†æ–‡ä»¶ç¼–å·ä¸”APIéªŒè¯å¤±è´¥ï¼‰
            if sec_accession_number and cik and not sec_api_validation_result:
                logger.info("æ‰§è¡ŒSECæ–‡ä»¶æ•°æ®éªŒè¯...")
                try:
                    sec_data = self.sec_validator.get_sec_filing_data(cik, sec_accession_number)
                    if sec_data:
                        sec_comparison = self.sec_validator.validate_against_sec_data(xbrl_data, sec_data)
                        validation_summary['validation_components']['sec_external'] = {
                            'match_rate': sec_comparison['overall_match_rate'],
                            'matches': len(sec_comparison['matches']),
                            'mismatches': len(sec_comparison['mismatches']),
                            'missing_in_sec': len(sec_comparison['missing_in_sec']),
                            'comparison_details': sec_comparison
                        }
                        sec_validation_result = sec_comparison
                    else:
                        logger.warning("æ— æ³•è·å–SECæ–‡ä»¶æ•°æ®è¿›è¡Œå¯¹æ¯”")
                except Exception as e:
                    logger.error(f"SECæ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
            
            # 3. å†å²è¶‹åŠ¿éªŒè¯ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
            historical_analysis = None
            if historical_data:
                logger.info("æ‰§è¡Œå†å²è¶‹åŠ¿éªŒè¯...")
                try:
                    trend_analyses = self.historical_validator.validate_historical_trends(xbrl_data, historical_data)
                    if trend_analyses:
                        issues = self.historical_validator.validate_reasonableness(trend_analyses)
                        anomalies = self.historical_validator.detect_financial_anomalies(trend_analyses)
                        
                        validation_summary['validation_components']['historical_trends'] = {
                            'analyzed_concepts': len(trend_analyses),
                            'trend_issues': len(issues),
                            'anomalies_detected': sum(len(anomaly_list) for anomaly_list in anomalies.values()),
                            'issues': issues,
                            'anomalies': anomalies,
                            'trend_analyses': {k: v.__dict__ for k, v in trend_analyses.items()}
                        }
                        historical_analysis = {
                            'trend_analyses': trend_analyses,
                            'issues': issues,
                            'anomalies': anomalies
                        }
                except Exception as e:
                    logger.error(f"å†å²è¶‹åŠ¿éªŒè¯å¤±è´¥: {e}")
            
            # è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦åˆ†æ•°
            overall_confidence = self._calculate_overall_confidence(validation_summary['validation_components'])
            validation_summary['overall_confidence_score'] = overall_confidence
            
            # ç¡®å®šéªŒè¯çŠ¶æ€
            validation_summary['validation_status'] = self._determine_validation_status(
                validation_summary['validation_components'], overall_confidence
            )
            
            # æ±‡æ€»æ‰€æœ‰é—®é¢˜
            validation_summary['issues_found'] = self._compile_all_issues(validation_summary['validation_components'])
            
            # ç”Ÿæˆå»ºè®®
            validation_summary['recommendations'] = self._generate_recommendations(validation_summary)
            
            logger.info(f"éªŒè¯å®Œæˆ: {company_name} {fiscal_year} - "
                       f"çŠ¶æ€={validation_summary['validation_status']}, "
                       f"ç½®ä¿¡åº¦={overall_confidence:.1%}")
            
            return validation_summary
            
        except Exception as e:
            logger.error(f"éªŒè¯è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}")
            validation_summary['validation_status'] = 'ERROR'
            validation_summary['issues_found'].append(f"éªŒè¯è¿‡ç¨‹é”™è¯¯: {str(e)}")
            return validation_summary
    
    def _calculate_overall_confidence(self, components: Dict[str, Any]) -> float:
        """è®¡ç®—æ€»ä½“ç½®ä¿¡åº¦åˆ†æ•°"""
        confidence_scores = []
        weights = {
            'internal_consistency': 0.4,
            'sec_api_external': 0.3,
            'sec_external': 0.2,
            'historical_trends': 0.1
        }
        
        for component_name, weight in weights.items():
            if component_name in components:
                component = components[component_name]
                
                if component_name == 'internal_consistency':
                    confidence_scores.append(component['confidence_score'] * weight)
                elif component_name == 'sec_api_external':
                    # APIéªŒè¯çš„æƒé‡åŸºäºåŒ¹é…ç‡å’ŒæŸ¥è¯¢æˆåŠŸç‡
                    match_rate = component['match_rate']
                    query_success_rate = component.get('query_success_rate', 1.0)
                    api_score = (match_rate * 0.7 + query_success_rate * 0.3) * weight
                    confidence_scores.append(api_score)
                elif component_name == 'sec_external':
                    confidence_scores.append(component['match_rate'] * weight)
                elif component_name == 'historical_trends':
                    # åŸºäºè¶‹åŠ¿åˆ†æé—®é¢˜çš„æ•°é‡è®¡ç®—åˆ†æ•°
                    total_issues = component.get('trend_issues', 0) + component.get('anomalies_detected', 0)
                    trend_score = max(0, 1 - total_issues * 0.1)  # æ¯ä¸ªé—®é¢˜æ‰£0.1åˆ†
                    confidence_scores.append(trend_score * weight)
        
        return sum(confidence_scores) if confidence_scores else 0.0
    
    def _determine_validation_status(self, components: Dict[str, Any], confidence_score: float) -> str:
        """ç¡®å®šéªŒè¯çŠ¶æ€"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡é”™è¯¯
        for component_name, component in components.items():
            if component_name == 'internal_consistency' and not component['passed']:
                return 'FAILED'
        
        # åŸºäºç½®ä¿¡åº¦åˆ†æ•°ç¡®å®šçŠ¶æ€
        if confidence_score >= 0.9:
            return 'EXCELLENT'
        elif confidence_score >= 0.8:
            return 'GOOD'
        elif confidence_score >= 0.6:
            return 'FAIR'
        else:
            return 'POOR'
    
    def _compile_all_issues(self, components: Dict[str, Any]) -> List[str]:
        """æ±‡æ€»æ‰€æœ‰é—®é¢˜"""
        all_issues = []
        
        for component_name, component in components.items():
            if component_name == 'internal_consistency':
                all_issues.extend([f"å†…éƒ¨é”™è¯¯: {error}" for error in component.get('errors', [])])
                all_issues.extend([f"å†…éƒ¨è­¦å‘Š: {warning}" for warning in component.get('warnings', [])])
            elif component_name == 'sec_external':
                mismatches = component.get('comparison_details', {}).get('mismatches', [])
                for mismatch in mismatches:
                    all_issues.append(
                        f"SECæ•°æ®ä¸åŒ¹é…: {mismatch['concept']} "
                        f"(å·®å¼‚: {mismatch['relative_difference']:.1%})"
                    )
            elif component_name == 'historical_trends':
                all_issues.extend(component.get('issues', []))
                
                # æ·»åŠ å¼‚å¸¸æ¨¡å¼
                anomalies = component.get('anomalies', {})
                for anomaly_type, anomaly_list in anomalies.items():
                    for anomaly in anomaly_list:
                        all_issues.append(f"å¼‚å¸¸æ¨¡å¼({anomaly_type}): {anomaly}")
        
        return all_issues
    
    def _generate_recommendations(self, validation_summary: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        status = validation_summary['validation_status']
        confidence = validation_summary['overall_confidence_score']
        
        if status == 'FAILED':
            recommendations.extend([
                "æ•°æ®å­˜åœ¨ä¸¥é‡é”™è¯¯ï¼Œå»ºè®®é‡æ–°è§£æXBRLæ–‡ä»¶",
                "æ£€æŸ¥åŸå§‹SECæ–‡ä»¶çš„å®Œæ•´æ€§",
                "è€ƒè™‘æ‰‹åŠ¨æ ¸å¯¹å…³é”®è´¢åŠ¡æ•°æ®"
            ])
        elif status == 'POOR':
            recommendations.extend([
                "æ•°æ®è´¨é‡è¾ƒå·®ï¼Œå»ºè®®è¿›è¡Œè¯¦ç»†æ ¸æŸ¥",
                "æ£€æŸ¥è§£æé…ç½®å’Œå‚æ•°è®¾ç½®",
                "è€ƒè™‘ä½¿ç”¨å…¶ä»–æ•°æ®æºè¿›è¡Œäº¤å‰éªŒè¯"
            ])
        elif status == 'FAIR':
            recommendations.extend([
                "æ•°æ®åŸºæœ¬å¯ç”¨ä½†å­˜åœ¨ä¸€äº›é—®é¢˜",
                "å…³æ³¨å…·ä½“è­¦å‘Šé¡¹å¹¶è¿›è¡Œå¿…è¦çš„äººå·¥æ ¸å¯¹",
                "å»ºè®®åœ¨é‡è¦å†³ç­–å‰è¿›ä¸€æ­¥éªŒè¯"
            ])
        elif status == 'GOOD':
            recommendations.extend([
                "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨",
                "å»ºè®®å®šæœŸæ›´æ–°éªŒè¯è§„åˆ™",
                "å¯ä»¥å¼€å§‹è¿›è¡Œè´¢åŠ¡åˆ†æ"
            ])
        elif status == 'EXCELLENT':
            recommendations.extend([
                "æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œä¸å¤–éƒ¨æ•°æ®é«˜åº¦ä¸€è‡´",
                "å¯ä»¥æ”¾å¿ƒç”¨äºè´¢åŠ¡åˆ†æå’Œå†³ç­–",
                "å»ºè®®å»ºç«‹æŒç»­çš„æ•°æ®è´¨é‡ç›‘æ§"
            ])
        
        # åŸºäºå…·ä½“é—®é¢˜çš„å»ºè®®
        components = validation_summary['validation_components']
        
        if 'internal_consistency' in components:
            internal = components['internal_consistency']
            if internal.get('errors'):
                recommendations.append("é‡ç‚¹å…³æ³¨å†…éƒ¨ä¸€è‡´æ€§é—®é¢˜ï¼Œæ£€æŸ¥æ•°æ®è®¡ç®—é€»è¾‘")
        
        if 'sec_api_external' in components:
            sec_api = components['sec_api_external']
            if sec_api.get('match_rate', 0) < 0.8:
                recommendations.append("SEC APIæ•°æ®åŒ¹é…åº¦è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥è§£æç²¾åº¦")
            elif sec_api.get('query_success_rate', 1.0) < 0.7:
                recommendations.append("SEC APIæŸ¥è¯¢æˆåŠŸç‡è¾ƒä½ï¼Œå¯èƒ½å½±å“éªŒè¯å‡†ç¡®æ€§")
        elif 'sec_external' in components:
            sec = components['sec_external']
            if sec.get('match_rate', 0) < 0.8:
                recommendations.append("SECæ•°æ®åŒ¹é…åº¦è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥è§£æç²¾åº¦")
        
        if 'historical_trends' in components:
            historical = components['historical_trends']
            if historical.get('anomalies_detected', 0) > 0:
                recommendations.append("å‘ç°å†å²è¶‹åŠ¿å¼‚å¸¸ï¼Œå»ºè®®ç»“åˆä¸šåŠ¡ç¯å¢ƒåˆ†æ")
        
        return recommendations
    
    def generate_comprehensive_report(self, validation_summary: Dict[str, Any], 
                                    output_dir: str = "./validation_reports") -> str:
        """ç”Ÿæˆç»¼åˆéªŒè¯æŠ¥å‘Š"""
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        company_name = validation_summary['company_name']
        fiscal_year = validation_summary['fiscal_year']
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        report_filename = f"{company_name.replace(' ', '_')}_{fiscal_year}_validation_report_{timestamp}.md"
        report_path = os.path.join(output_dir, report_filename)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._generate_report_content(validation_summary)
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        # åŒæ—¶ä¿å­˜JSONæ ¼å¼çš„è¯¦ç»†ç»“æœ
        json_filename = f"{company_name.replace(' ', '_')}_{fiscal_year}_validation_data_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(validation_summary, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"éªŒè¯æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        self.reports_generated.append(report_path)
        
        return report_path
    
    def _generate_report_content(self, validation_summary: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ¥å‘Šå†…å®¹"""
        report = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        report.append(f"# {validation_summary['company_name']} {validation_summary['fiscal_year']}å¹´åº¦")
        report.append("# è´¢åŠ¡æ•°æ®äº¤å‰éªŒè¯ç»¼åˆæŠ¥å‘Š")
        report.append("")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {validation_summary['validation_timestamp']}")
        report.append(f"**å…¬å¸CIK**: {validation_summary['cik']}")
        report.append(f"**éªŒè¯çŠ¶æ€**: {self._format_status(validation_summary['validation_status'])}")
        report.append(f"**æ€»ä½“ç½®ä¿¡åº¦**: {validation_summary['overall_confidence_score']:.1%}")
        report.append("")
        
        # æ‰§è¡Œæ‘˜è¦
        report.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦")
        report.append(self._generate_executive_summary(validation_summary))
        report.append("")
        
        # éªŒè¯ç»“æœè¯¦æƒ…
        components = validation_summary['validation_components']
        
        if 'internal_consistency' in components:
            report.append(self._generate_internal_section(components['internal_consistency']))
        
        if 'sec_api_external' in components:
            report.append(self._generate_sec_api_section(components['sec_api_external']))
        elif 'sec_external' in components:
            report.append(self._generate_sec_section(components['sec_external']))
        
        if 'historical_trends' in components:
            report.append(self._generate_historical_section(components['historical_trends']))
        
        # é—®é¢˜æ±‡æ€»
        if validation_summary['issues_found']:
            report.append("## âŒ é—®é¢˜æ±‡æ€»")
            for i, issue in enumerate(validation_summary['issues_found'], 1):
                report.append(f"{i}. {issue}")
            report.append("")
        
        # å»ºè®®å’Œåç»­æ­¥éª¤
        if validation_summary['recommendations']:
            report.append("## ğŸ’¡ æ”¹è¿›å»ºè®®")
            for i, recommendation in enumerate(validation_summary['recommendations'], 1):
                report.append(f"{i}. {recommendation}")
            report.append("")
        
        # ç»“è®º
        report.append("## ğŸ¯ ç»“è®º")
        report.append(self._generate_conclusion(validation_summary))
        
        return "\n".join(report)
    
    def _format_status(self, status: str) -> str:
        """æ ¼å¼åŒ–çŠ¶æ€æ˜¾ç¤º"""
        status_map = {
            'EXCELLENT': 'âœ… ä¼˜ç§€',
            'GOOD': 'âœ… è‰¯å¥½',
            'FAIR': 'âš ï¸ ä¸€èˆ¬',
            'POOR': 'âŒ è¾ƒå·®',
            'FAILED': 'âŒ å¤±è´¥',
            'ERROR': 'âŒ é”™è¯¯'
        }
        return status_map.get(status, status)
    
    def _generate_executive_summary(self, validation_summary: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        status = validation_summary['validation_status']
        confidence = validation_summary['overall_confidence_score']
        issues_count = len(validation_summary['issues_found'])
        
        summary_parts = [
            f"æ•°æ®éªŒè¯çŠ¶æ€ä¸º**{self._format_status(status)}**ï¼Œ",
            f"æ€»ä½“ç½®ä¿¡åº¦åˆ†æ•°ä¸º**{confidence:.1%}**ã€‚"
        ]
        
        if issues_count == 0:
            summary_parts.append("æœªå‘ç°æ˜æ˜¾é—®é¢˜ï¼Œæ•°æ®è´¨é‡è‰¯å¥½ã€‚")
        else:
            summary_parts.append(f"å‘ç°**{issues_count}ä¸ªé—®é¢˜**éœ€è¦å…³æ³¨ã€‚")
        
        return "".join(summary_parts)
    
    def _generate_internal_section(self, internal_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå†…éƒ¨ä¸€è‡´æ€§éªŒè¯éƒ¨åˆ†"""
        section = ["## ğŸ” å†…éƒ¨ä¸€è‡´æ€§éªŒè¯"]
        section.append("")
        
        status = "âœ… é€šè¿‡" if internal_data['passed'] else "âŒ å¤±è´¥"
        section.append(f"**éªŒè¯çŠ¶æ€**: {status}")
        section.append(f"**ç½®ä¿¡åº¦åˆ†æ•°**: {internal_data['confidence_score']:.1%}")
        section.append("")
        
        if internal_data.get('errors'):
            section.append("### é”™è¯¯")
            for error in internal_data['errors']:
                section.append(f"- âŒ {error}")
            section.append("")
        
        if internal_data.get('warnings'):
            section.append("### è­¦å‘Š")
            for warning in internal_data['warnings']:
                section.append(f"- âš ï¸ {warning}")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_sec_api_section(self, sec_api_data: Dict[str, Any]) -> str:
        """ç”ŸæˆSEC APIéªŒè¯éƒ¨åˆ†"""
        section = ["## ğŸŒ SEC APIæ•°æ®éªŒè¯"]
        section.append("")
        
        match_rate = sec_api_data['match_rate']
        query_success_rate = sec_api_data.get('query_success_rate', 1.0)
        matches = sec_api_data['matches']
        mismatches = sec_api_data['mismatches']
        
        section.append(f"**APIæ•°æ®åŒ¹é…ç‡**: {match_rate:.1%}")
        section.append(f"**APIæŸ¥è¯¢æˆåŠŸç‡**: {query_success_rate:.1%}")
        section.append(f"**åŒ¹é…é¡¹æ•°**: {matches}")
        section.append(f"**ä¸åŒ¹é…é¡¹æ•°**: {mismatches}")
        section.append("")
        
        # APIæŸ¥è¯¢è¯¦æƒ…
        query_details = sec_api_data.get('comparison_details', {}).get('api_query_details', [])
        if query_details:
            successful_queries = sum(1 for q in query_details if q.get('query_successful', False))
            total_queries = len(query_details)
            
            section.append(f"### APIæŸ¥è¯¢ç»Ÿè®¡")
            section.append(f"- æ€»æŸ¥è¯¢æ¬¡æ•°: {total_queries}")
            section.append(f"- æˆåŠŸæŸ¥è¯¢: {successful_queries}")
            section.append(f"- å¤±è´¥æŸ¥è¯¢: {total_queries - successful_queries}")
            section.append("")
            
            # å¤±è´¥æŸ¥è¯¢
            failed_queries = [q for q in query_details if not q.get('query_successful', False)]
            if failed_queries:
                section.append("### APIæŸ¥è¯¢å¤±è´¥é¡¹")
                for query in failed_queries[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    section.append(f"- {query['concept']} -> {query['api_concept']}: {query['reason']}")
                section.append("")
        
        # ä¸åŒ¹é…é¡¹è¯¦æƒ…
        if mismatches > 0:
            section.append("### ä¸»è¦ä¸åŒ¹é…é¡¹")
            comparison = sec_api_data['comparison_details']
            for mismatch in comparison['api_mismatches'][:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                concept = mismatch['concept']
                diff_pct = mismatch['relative_difference'] * 100
                section.append(f"- {concept}: å·®å¼‚ {diff_pct:.1f}%")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_sec_section(self, sec_data: Dict[str, Any]) -> str:
        """ç”ŸæˆSECéªŒè¯éƒ¨åˆ†"""
        section = ["## ğŸŒ SECå®˜ç½‘æ•°æ®éªŒè¯"]
        section.append("")
        
        match_rate = sec_data['match_rate']
        section.append(f"**æ•°æ®åŒ¹é…ç‡**: {match_rate:.1%}")
        section.append(f"**åŒ¹é…é¡¹æ•°**: {sec_data['matches']}")
        section.append(f"**ä¸åŒ¹é…é¡¹æ•°**: {sec_data['mismatches']}")
        section.append("")
        
        if sec_data['mismatches'] > 0:
            section.append("### ä¸»è¦ä¸åŒ¹é…é¡¹")
            comparison = sec_data['comparison_details']
            for mismatch in comparison['mismatches'][:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                concept = mismatch['concept']
                diff_pct = mismatch['relative_difference'] * 100
                section.append(f"- {concept}: å·®å¼‚ {diff_pct:.1f}%")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_historical_section(self, historical_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå†å²è¶‹åŠ¿éªŒè¯éƒ¨åˆ†"""
        section = ["## ğŸ“ˆ å†å²è¶‹åŠ¿éªŒè¯"]
        section.append("")
        
        analyzed_concepts = historical_data['analyzed_concepts']
        trend_issues = historical_data['trend_issues']
        anomalies_detected = historical_data['anomalies_detected']
        
        section.append(f"**åˆ†ææŒ‡æ ‡æ•°**: {analyzed_concepts}")
        section.append(f"**è¶‹åŠ¿é—®é¢˜**: {trend_issues}")
        section.append(f"**å¼‚å¸¸æ¨¡å¼**: {anomalies_detected}")
        section.append("")
        
        if historical_data.get('anomalies'):
            section.append("### æ£€æµ‹åˆ°çš„å¼‚å¸¸æ¨¡å¼")
            for anomaly_type, anomalies in historical_data['anomalies'].items():
                if anomalies:
                    section.append(f"#### {anomaly_type.replace('_', ' ').title()}")
                    for anomaly in anomalies[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                        section.append(f"- {anomaly}")
            section.append("")
        
        return "\n".join(section)
    
    def _generate_conclusion(self, validation_summary: Dict[str, Any]) -> str:
        """ç”Ÿæˆç»“è®º"""
        status = validation_summary['validation_status']
        confidence = validation_summary['overall_confidence_score']
        issues_count = len(validation_summary['issues_found'])
        
        if status == 'EXCELLENT':
            return "æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œä¸å„ç§éªŒè¯æ ‡å‡†é«˜åº¦ä¸€è‡´ï¼Œå¯ä»¥æ”¾å¿ƒç”¨äºè´¢åŠ¡åˆ†æå’Œå†³ç­–ã€‚"
        elif status == 'GOOD':
            return "æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå­˜åœ¨å°‘é‡ä¸å½±å“ä¸»è¦åˆ†æçš„å·®å¼‚ï¼Œå»ºè®®åœ¨é‡è¦å†³ç­–å‰ç¡®è®¤å…³é”®æŒ‡æ ‡ã€‚"
        elif status == 'FAIR':
            return "æ•°æ®åŸºæœ¬å¯ç”¨ä½†å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨è­¦å‘Šé¡¹å¹¶åœ¨å¿…è¦æ—¶è¿›è¡Œäººå·¥æ ¸å¯¹ã€‚"
        elif status == 'POOR':
            return "æ•°æ®è´¨é‡å­˜åœ¨æ˜æ˜¾é—®é¢˜ï¼Œå»ºè®®é‡æ–°è§£ææ•°æ®æˆ–ä½¿ç”¨å…¶ä»–æ•°æ®æºè¿›è¡ŒéªŒè¯ã€‚"
        else:
            return "æ•°æ®éªŒè¯å¤±è´¥ï¼Œå­˜åœ¨ä¸¥é‡é”™è¯¯ï¼Œä¸å»ºè®®ä½¿ç”¨å½“å‰æ•°æ®è¿›è¡Œé‡è¦åˆ†æã€‚"


def main():
    """ç¤ºä¾‹ä½¿ç”¨"""
    # æ¨¡æ‹Ÿæ•°æ®
    xbrl_data = {
        'RevenueFromContractWithCustomerExcludingAssessedTax': {'value': 394328000000},
        'NetIncomeLoss': {'value': 99980000000},
        'Assets': {'value': 352583000000},
        'Liabilities': {'value': 290437000000},
        'StockholdersEquity': {'value': 62146000000}
    }
    
    company_info = {
        'name': 'Apple Inc.',
        'cik': '0000320193',
        'fiscal_year': 2024
    }
    
    historical_data = [
        {'RevenueFromContractWithCustomerExcludingAssessedTax': {'value': 383285000000},
         'NetIncomeLoss': {'value': 96995000000},
         'Assets': {'value': 365725000000},
         'Liabilities': {'value': 302083000000}},
        {'RevenueFromContractWithCustomerExcludingAssessedTax': {'value': 365817000000},
         'NetIncomeLoss': {'value': 94680000000},
         'Assets': {'value': 352755000000},
         'Liabilities': {'value': 287912000000}}
    ]
    
    # åˆ›å»ºåè°ƒå™¨å¹¶æ‰§è¡ŒéªŒè¯
    orchestrator = ValidationOrchestrator()
    result = orchestrator.validate_xbrl_document(
        xbrl_data=xbrl_data,
        company_info=company_info,
        historical_data=historical_data,
        sec_accession_number="0000320193-24-000123"  # ç¤ºä¾‹æ–‡ä»¶ç¼–å·
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = orchestrator.generate_comprehensive_report(result)
    print(f"éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


if __name__ == "__main__":
    main()